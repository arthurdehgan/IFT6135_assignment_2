{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_A2_P5_1_2_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "XC-zVAkYA1bX",
        "IL_kMTKvqhBO",
        "EOOJHAVZBJAr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "XC-zVAkYA1bX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import data"
      ]
    },
    {
      "metadata": {
        "id": "MFcGHrWtAygp",
        "colab_type": "code",
        "outputId": "19965e8f-39f8-4a8c-f527-35d14b8239f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/IanPorada/IFT6135_assignment_2.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IFT6135_assignment_2'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 12 (delta 2), reused 2 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (12/12), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w_X4JQIpBVho",
        "colab_type": "code",
        "outputId": "13d684fc-4a65-4390-ea32-b919a51a0bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd IFT6135_assignment_2/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/IFT6135_assignment_2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N6LIBHnLY4bX",
        "colab_type": "code",
        "outputId": "77ca21ba-4212-46c3-98a2-da8daebbb8c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ICKOxb4MZWPQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/My Drive/PB4_1/\" ./PB4_1/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E7i3uYzzjjH7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IL_kMTKvqhBO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Models"
      ]
    },
    {
      "metadata": {
        "id": "uy22Ud1wO8ux",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grads = []\n",
        "def my_hook(grad):\n",
        "    grads.append(grad.norm().item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mH5nsqeAqf1F",
        "colab_type": "code",
        "outputId": "dca6839c-a283-4f9d-9950-a3e5b0ba3791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import math, copy, time\n",
        "from torch.autograd import Variable\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Use the GPU if you have one\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using the GPU\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\n",
        "        \"WARNING: You are about to run on cpu, and this will likely run out \\\n",
        "      of memory. \\n You can try setting batch_size=1 to reduce memory usage\"\n",
        "    )\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "def clones(module, N):\n",
        "    \"A helper function for producing N identical layers (each with their own parameters).\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
        "\n",
        "\n",
        "# Problem 1\n",
        "class RNN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        emb_size,\n",
        "        hidden_size,\n",
        "        seq_len,\n",
        "        batch_size,\n",
        "        vocab_size,\n",
        "        num_layers,\n",
        "        dp_keep_prob,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        emb_size:     The numvwe of units in the input embeddings\n",
        "        hidden_size:  The number of hidden units per layer\n",
        "        seq_len:      The length of the input sequences\n",
        "        vocab_size:   The number of tokens in the vocabulary (10,000 for Penn TreeBank)\n",
        "        num_layers:   The depth of the stack (i.e. the number of hidden layers at\n",
        "                      each time-step)\n",
        "        dp_keep_prob: The probability of *not* dropping out units in the\n",
        "                      non-recurrent connections.\n",
        "                      Do not apply dropout on recurrent connections.\n",
        "        \"\"\"\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.emb_size = emb_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_len = seq_len\n",
        "        self.batch_size = batch_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dp_keep_prob = dp_keep_prob\n",
        "\n",
        "        # model = nn.ModuleDict().to(device)\n",
        "        # self.embedding = WordEmbedding(emb_size, vocab_size).to(device)\n",
        "        # input_size = emb_size\n",
        "        # for i in range(num_layers):\n",
        "        # model[f\"Wx{i}\"] = nn.Linear(input_size, hidden_size)\n",
        "        # model[f\"Wh{i}\"] = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        # input_size = hidden_size\n",
        "        # self.fc = nn.Linear(hidden_size, vocab_size).to(device)\n",
        "        # self.dropout = nn.Dropout(1 - dp_keep_prob).to(device)\n",
        "        # self.tanh = nn.Tanh().to(device)\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size).to(device)\n",
        "        first_layer = nn.Linear(self.emb_size + self.hidden_size, self.hidden_size).to(\n",
        "            device\n",
        "        )\n",
        "        self.model_rnn = nn.ModuleList([first_layer]).to(device)\n",
        "        rest_layer = nn.Linear(2 * self.hidden_size, self.hidden_size).to(device)\n",
        "        self.model_rnn.extend(clones(rest_layer, self.num_layers - 1))  # RNN Layer\n",
        "\n",
        "        self.linear_layers = clones(\n",
        "            nn.Linear(hidden_size, hidden_size), num_layers - 1\n",
        "        ).to(\n",
        "            device\n",
        "        )  # FC Layers\n",
        "        self.linear_layers.append(nn.Linear(hidden_size, vocab_size))\n",
        "\n",
        "        self.dropout_layers = clones(nn.Dropout(p=1 - dp_keep_prob), num_layers).to(\n",
        "            device\n",
        "        )  # Dropout Layers :\n",
        "        self.input_emb = nn.Dropout(p=1 - dp_keep_prob).to(device)\n",
        "\n",
        "        self.init_weights_uniform()\n",
        "\n",
        "    def init_weights_uniform(self):\n",
        "        torch.nn.init.uniform_(self.embedding.weight, -0.1, 0.1)\n",
        "        # nn.init.uniform_(self.embedding.lut.weight, -0.1, 0.1)\n",
        "        # nn.init.uniform_(self.fc.weight, -0.1, 0.1)\n",
        "        # nn.init.zeros_(self.fc.bias)\n",
        "        torch.nn.init.uniform_(self.linear_layers[-1].weight, -0.1, 0.1)\n",
        "        torch.nn.init.zeros_(self.linear_layers[-1].bias)\n",
        "\n",
        "        for layer in self.model_rnn:\n",
        "            for param in layer.modules():\n",
        "                if type(param) == nn.Linear:\n",
        "                    torch.nn.init.uniform_(\n",
        "                        param.weight,\n",
        "                        -math.sqrt(1 / self.hidden_size),\n",
        "                        math.sqrt(1 / self.hidden_size),\n",
        "                    )\n",
        "                    if param.bias is not None:\n",
        "                        torch.nn.init.uniform_(\n",
        "                            param.bias,\n",
        "                            -math.sqrt(1 / self.hidden_size),\n",
        "                            math.sqrt(1 / self.hidden_size),\n",
        "                        )\n",
        "\n",
        "    def init_hidden(self):\n",
        "        \"\"\"\n",
        "        This is used for the first mini-batch in an epoch, only.\n",
        "        \"\"\"\n",
        "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(\n",
        "            device\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs, hidden):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            - inputs: A mini-batch of input sequences, composed of integers that\n",
        "                        represent the index of the current token(s) in the vocabulary.\n",
        "                            shape: (seq_len, batch_size)\n",
        "            - hidden: The initial hidden states for every layer of the stacked RNN.\n",
        "                            shape: (num_layers, batch_size, hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            - Logits for the softmax over output tokens at every time-step.\n",
        "                  **Do NOT apply softmax to the outputs!**\n",
        "                  Pytorch's CrossEntropyLoss function (applied in ptb-lm.py) does\n",
        "                  this computation implicitly.\n",
        "                        shape: (seq_len, batch_size, vocab_size)\n",
        "            - The final hidden states for every layer of the stacked RNN.\n",
        "                  These will be used as the initial hidden states for all the\n",
        "                  mini-batches in an epoch, except for the first, where the return\n",
        "                  value of self.init_hidden will be used.\n",
        "                  See the repackage_hiddens function in ptb-lm.py for more details,\n",
        "                  if you are curious.\n",
        "                        shape: (num_layers, batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        # timesteps = len(inputs)\n",
        "        # logits = torch.zeros(\n",
        "        # (self.seq_len, self.batch_size, self.vocab_size), requires_grad=True\n",
        "        # ).to(device)\n",
        "        # inputs = self.dropout(self.embedding(inputs))\n",
        "        # for ts in range(timesteps):\n",
        "        # ts_input = inputs[ts]\n",
        "        # for i in range(self.num_layers):\n",
        "        # hidden[i] = self.tanh(\n",
        "        # self.model[f\"Wx{i}\"](ts_input)\n",
        "        # + self.model[f\"Wh{i}\"](hidden[i].clone())\n",
        "        # )\n",
        "        # ts_input = self.dropout(hidden[i].clone())\n",
        "        # logits[ts] = self.fc(ts_input)\n",
        "\n",
        "        emb_inputs = self.embedding(inputs)\n",
        "        emb_inputs = self.input_emb(emb_inputs)\n",
        "\n",
        "        logits = torch.zeros(\n",
        "            [self.seq_len, self.batch_size, self.vocab_size],\n",
        "            dtype=hidden.dtype,\n",
        "            device=hidden.device,\n",
        "        )\n",
        "\n",
        "        for seq in range(self.seq_len):\n",
        "            for j in range(self.num_layers):\n",
        "                if j == 0:\n",
        "\n",
        "                    next_hidden = torch.tanh(\n",
        "                        self.model_rnn[j](torch.cat([hidden[j], emb_inputs[seq]], 1))\n",
        "                    )\n",
        "                    next_hidden.register_hook(my_hook)\n",
        "                    hidden[j] = next_hidden\n",
        "                    outputs = self.dropout_layers[j](hidden[j])\n",
        "                    # outputs.register_hook(my_hook)\n",
        "                else:\n",
        "\n",
        "                    next_hidden = torch.tanh(\n",
        "                        self.model_rnn[j](torch.cat([hidden[j], outputs], 1))\n",
        "                    )\n",
        "                    next_hidden.register_hook(my_hook)\n",
        "                    hidden[j] = next_hidden\n",
        "                    outputs = self.dropout_layers[j](hidden[j])\n",
        "                    \n",
        "                    if j == self.num_layers - 1:\n",
        "\n",
        "                        logits[seq] = self.linear_layers[j](outputs)\n",
        "        return logits.view(self.seq_len, self.batch_size, self.vocab_size), hidden\n",
        "\n",
        "    def generate(self, inputs, hidden, generated_seq_len):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            - input: A mini-batch of input tokens (NOT sequences!)\n",
        "                            shape: (batch_size)\n",
        "            - hidden: The initial hidden states for every layer of the stacked RNN.\n",
        "                            shape: (num_layers, batch_size, hidden_size)\n",
        "            - generated_seq_len: The length of the sequence to generate.\n",
        "                           Note that this can be different than the length used\n",
        "                           for training (self.seq_len)\n",
        "        Returns:\n",
        "            - Sampled sequences of tokens\n",
        "                        shape: (generated_seq_len, batch_size)\n",
        "        \"\"\"\n",
        "        samples = []\n",
        "        orig_seq_len = self.seq_len\n",
        "        self.seq_len = 1\n",
        "        seed = inputs.view(1, *inputs.shape)\n",
        "        for i in range(generated_seq_len):\n",
        "            samples.append(\n",
        "                torch.max(nn.Softmax(2)(self.forward(seed, hidden)[0]), 2)[1]\n",
        "            )\n",
        "            seed = samples[-1]\n",
        "\n",
        "        self.seq_len = orig_seq_len\n",
        "        samples = torch.stack(samples)\n",
        "        return samples\n",
        "\n",
        "\n",
        "# Problem 2\n",
        "class GRU(nn.Module):  # Implement a stacked GRU RNN\n",
        "    \"\"\"\n",
        "    Follow the same instructions as for RNN (above), but use the equations for\n",
        "    GRU, not Vanilla RNN.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        emb_size,\n",
        "        hidden_size,\n",
        "        seq_len,\n",
        "        batch_size,\n",
        "        vocab_size,\n",
        "        num_layers,\n",
        "        dp_keep_prob,\n",
        "    ):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.emb_size = emb_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_len = seq_len\n",
        "        self.batch_size = batch_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dp_keep_prob = dp_keep_prob\n",
        "\n",
        "        # self.embedding = WordEmbedding(emb_size, vocab_size).to(\n",
        "        #     device\n",
        "        # )  # Word Embedding Layer\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size).to(device)\n",
        "\n",
        "        self.model = nn.ModuleDict().to(device)\n",
        "        input_size = self.emb_size\n",
        "        for i in range(self.num_layers):\n",
        "            self.model[f\"Wr{i}\"] = nn.Linear(input_size, hidden_size)\n",
        "            self.model[f\"Ur{i}\"] = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "            self.model[f\"Wz{i}\"] = nn.Linear(input_size, hidden_size)\n",
        "            self.model[f\"Uz{i}\"] = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "            self.model[f\"Wh{i}\"] = nn.Linear(input_size, hidden_size)\n",
        "            self.model[f\"Uh{i}\"] = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "            input_size = hidden_size\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size).to(device)\n",
        "        self.dropout = nn.Dropout(p=1 - dp_keep_prob).to(device)\n",
        "        self.tanh = nn.Tanh().to(device)\n",
        "        self.sigm = nn.Sigmoid().to(device)\n",
        "\n",
        "        self.init_weights_uniform()\n",
        "\n",
        "    def init_weights_uniform(self):\n",
        "        nn.init.uniform_(self.embedding.weight, -0.1, 0.1)\n",
        "        nn.init.uniform_(self.fc.weight, -0.1, 0.1)\n",
        "        nn.init.zeros_(self.fc.bias)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(\n",
        "            device\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs, hidden):\n",
        "        logits = torch.zeros(\n",
        "            [self.seq_len, self.batch_size, self.vocab_size], requires_grad=True\n",
        "        ).to(device)\n",
        "        for seq in range(self.seq_len):\n",
        "            ts_input = self.dropout(self.embedding(inputs[seq]))\n",
        "            for i in range(self.num_layers):\n",
        "                r = self.sigm(\n",
        "                    self.model[f\"Wr{i}\"](ts_input)\n",
        "                    + self.model[f\"Ur{i}\"](hidden[i].clone())\n",
        "                )\n",
        "                z = self.sigm(\n",
        "                    self.model[f\"Wz{i}\"](ts_input)\n",
        "                    + self.model[f\"Uz{i}\"](hidden[i].clone())\n",
        "                )\n",
        "                h = self.tanh(\n",
        "                    self.model[f\"Wh{i}\"](ts_input)\n",
        "                    + self.model[f\"Uh{i}\"](r * hidden[i].clone())\n",
        "                )\n",
        "                next_hidden = (1 - z) * hidden[i].clone() + z * h\n",
        "                next_hidden.register_hook(my_hook)\n",
        "                hidden[i] = next_hidden\n",
        "                outputs = self.dropout(hidden[i])\n",
        "                ts_input = outputs\n",
        "            logits[seq] = self.fc(outputs)\n",
        "        return logits.view(self.seq_len, self.batch_size, self.vocab_size), hidden\n",
        "\n",
        "    def generate(self, inputs, hidden, generated_seq_len):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            - input: A mini-batch of input tokens (NOT sequences!)\n",
        "                            shape: (batch_size)\n",
        "            - hidden: The initial hidden states for every layer of the stacked RNN.\n",
        "                            shape: (num_layers, batch_size, hidden_size)\n",
        "            - generated_seq_len: The length of the sequence to generate.\n",
        "                           Note that this can be different than the length used\n",
        "                           for training (self.seq_len)\n",
        "        Returns:\n",
        "            - Sampled sequences of tokens\n",
        "                        shape: (generated_seq_len, batch_size)\n",
        "        \"\"\"\n",
        "        samples = []\n",
        "        orig_seq_len = self.seq_len\n",
        "        self.seq_len = 1\n",
        "        seed = inputs.view(1, *inputs.shape)\n",
        "        for i in range(generated_seq_len):\n",
        "            samples.append(\n",
        "                torch.max(nn.Softmax(2)(self.forward(seed, hidden)[0]), 2)[1]\n",
        "            )\n",
        "            seed = samples[-1]\n",
        "\n",
        "        self.seq_len = orig_seq_len\n",
        "        samples = torch.stack(samples)\n",
        "        return samples\n",
        "\n",
        "\n",
        "# Problem 3\n",
        "##############################################################################\n",
        "#\n",
        "# Code for the Transformer model\n",
        "#\n",
        "##############################################################################\n",
        "\n",
        "\"\"\"\n",
        "Implement the MultiHeadedAttention module of the transformer architecture.\n",
        "All other necessary modules have already been implemented for you.\n",
        "\n",
        "We're building a transfomer architecture for next-step prediction tasks, and\n",
        "applying it to sequential language modelling. We use a binary \"mask\" to specify\n",
        "which time-steps the model can use for the current prediction.\n",
        "This ensures that the model only attends to previous time-steps.\n",
        "\n",
        "The model first encodes inputs using the concatenation of a learned WordEmbedding\n",
        "and a (in our case, hard-coded) PositionalEncoding.\n",
        "The word embedding maps a word's one-hot encoding into a dense real vector.\n",
        "The positional encoding 'tags' each element of an input sequence with a code that\n",
        "identifies it's position (i.e. time-step).\n",
        "\n",
        "These encodings of the inputs are then transformed repeatedly using multiple\n",
        "copies of a TransformerBlock.\n",
        "This block consists of an application of MultiHeadedAttention, followed by a\n",
        "standard MLP; the MLP applies *the same* mapping at every position.\n",
        "Both the attention and the MLP are applied with Resnet-style skip connections,\n",
        "and layer normalization.\n",
        "\n",
        "The complete model consists of the embeddings, the stacked transformer blocks,\n",
        "and a linear layer followed by a softmax.\n",
        "\"\"\"\n",
        "\n",
        "# This code has been modified from an open-source project, by David Krueger.\n",
        "# The original license is included below:\n",
        "# MIT License\n",
        "#\n",
        "# Copyright (c) 2018 Alexander Rush\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in all\n",
        "# copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "# SOFTWARE.\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "\n",
        "# implement this class\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, n_heads, n_units, dropout=0.1):\n",
        "        \"\"\"\n",
        "        n_heads: the number of attention heads\n",
        "        n_units: the number of output units\n",
        "        dropout: probability of DROPPING units\n",
        "        \"\"\"\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        # This sets the size of the keys, values, and queries (self.d_k) to all\n",
        "        # be equal to the number of output units divided by the number of heads.\n",
        "        self.d_k = n_units // n_heads\n",
        "        # This requires the number of n_heads to evenly divide n_units.\n",
        "        assert n_units % n_heads == 0\n",
        "        self.n_units = n_units\n",
        "\n",
        "        # create/initialize any necessary parameters or layers\n",
        "        # Note: the only Pytorch modules you are allowed to use are nn.Linear\n",
        "        # and nn.Dropout\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        # Create 4 embedding layers. One for each of Q, K, V, and output.\n",
        "        embedding_layer = nn.Linear(n_units, n_units)\n",
        "        self.embedding_layers = clones(embedding_layer, 4)\n",
        "\n",
        "        ki = np.sqrt(1 / n_units)\n",
        "        for l in self.embedding_layers:\n",
        "            nn.init.uniform_(l.weight, -ki, ki)\n",
        "\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "\n",
        "    # A single attention head given Q, K, V embeddings\n",
        "    def SingleAttention(self, query, key, value, mask=None, dropout_layer=None):\n",
        "        # Matrix multiply Q and K\n",
        "        soft_attention = torch.matmul(query, key)\n",
        "\n",
        "        # Scale soft attention\n",
        "        soft_attention = soft_attention / np.sqrt(self.d_k)\n",
        "\n",
        "        # Mask\n",
        "        epsilon = 1e9\n",
        "        if mask is not None:\n",
        "            # soft_attention = torch.mul(soft_attention, mask)\n",
        "            # Subtract epsilon for numerical stability.\n",
        "            # soft_attention = soft_attention - eps * (1 - mask)\n",
        "            # we can simply use masked fill following the given\n",
        "            # implementation with epsilon as per the assignment description\n",
        "            soft_attention = soft_attention.masked_fill(mask == 0, -epsilon)\n",
        "\n",
        "        # Softmax on the ouputs\n",
        "        soft_attention = F.softmax(soft_attention, dim=-1)\n",
        "\n",
        "        # Dropout\n",
        "        if dropout_layer is not None:\n",
        "            soft_attention = dropout_layer(soft_attention)\n",
        "\n",
        "        # Apply attention\n",
        "        output = torch.matmul(soft_attention, value)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        # implement the masked multi-head attention.\n",
        "        # query, key, and value all have size: (batch_size, seq_len, self.n_units, self.d_k)\n",
        "        # mask has size: (batch_size, seq_len, seq_len)\n",
        "        # As described in the .tex, apply input masking to the softmax\n",
        "        # generating the \"attention values\" (i.e. A_i in the .tex)\n",
        "        # Also apply dropout to the attention values.\n",
        "\n",
        "        batch_size = query.size(0)\n",
        "        seq_len = query.size(1)\n",
        "\n",
        "        if mask is not None:\n",
        "            # Same mask applied to all h heads.\n",
        "            # mask = mask.view(batch_size, 1, seq_len, seq_len)\n",
        "            mask = mask.unsqueeze(1)\n",
        "\n",
        "        query_embedding = (\n",
        "            self.embedding_layers[0](query)\n",
        "            .view(batch_size, seq_len, self.n_heads, self.d_k)\n",
        "            .transpose(1, 2)\n",
        "        )\n",
        "\n",
        "        key_embedding = (\n",
        "            self.embedding_layers[1](key)\n",
        "            .view(batch_size, seq_len, self.n_heads, self.d_k)\n",
        "            .transpose(1, 2)\n",
        "            .transpose(-2, -1)\n",
        "        )\n",
        "\n",
        "        value_embedding = (\n",
        "            self.embedding_layers[2](value)\n",
        "            .view(batch_size, seq_len, self.n_heads, self.d_k)\n",
        "            .transpose(1, 2)\n",
        "        )\n",
        "\n",
        "        output = self.SingleAttention(\n",
        "            query_embedding, key_embedding, value_embedding, mask, self.dropout_layer\n",
        "        ).transpose(1, 2)\n",
        "        # Concatenate outputs for each head\n",
        "        output = output.contiguous().view(batch_size, seq_len, self.n_heads * self.d_k)\n",
        "\n",
        "        output_embedding = self.embedding_layers[3](output)\n",
        "\n",
        "        return output_embedding\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "# The encodings of elements of the input sequence\n",
        "\n",
        "\n",
        "class WordEmbedding(nn.Module):\n",
        "    def __init__(self, n_units, vocab):\n",
        "        super(WordEmbedding, self).__init__()\n",
        "        self.lut = nn.Embedding(vocab, n_units)\n",
        "        self.n_units = n_units\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print (x)\n",
        "        return self.lut(x) * math.sqrt(self.n_units)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, n_units, dropout, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, n_units)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, n_units, 2).float() * -(math.log(10000.0) / n_units)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + Variable(self.pe[:, : x.size(1)], requires_grad=False)\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "# The TransformerBlock and the full Transformer\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(ResidualSkipConnectionWithLayerNorm(size, dropout), 2)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.sublayer[0](\n",
        "            x, lambda x: self.self_attn(x, x, x, mask)\n",
        "        )  # apply the self-attention\n",
        "        return self.sublayer[1](x, self.feed_forward)  # apply the position-wise MLP\n",
        "\n",
        "\n",
        "class TransformerStack(nn.Module):\n",
        "    \"\"\"\n",
        "    This will be called on the TransformerBlock (above) to create a stack.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layer, n_blocks):  # layer will be TransformerBlock (below)\n",
        "        super(TransformerStack, self).__init__()\n",
        "        self.layers = clones(layer, n_blocks)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "\n",
        "class FullTransformer(nn.Module):\n",
        "    def __init__(self, transformer_stack, embedding, n_units, vocab_size):\n",
        "        super(FullTransformer, self).__init__()\n",
        "        self.transformer_stack = transformer_stack\n",
        "        self.embedding = embedding\n",
        "        self.output_layer = nn.Linear(n_units, vocab_size)\n",
        "\n",
        "    def forward(self, input_sequence, mask):\n",
        "        embeddings = self.embedding(input_sequence)\n",
        "        return F.log_softmax(\n",
        "            self.output_layer(self.transformer_stack(embeddings, mask)), dim=-1\n",
        "        )\n",
        "\n",
        "\n",
        "def make_model(vocab_size, n_blocks=6, n_units=512, n_heads=16, dropout=0.1):\n",
        "    \"Helper: Construct a model from hyperparameters.\"\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadedAttention(n_heads, n_units)\n",
        "    ff = MLP(n_units, dropout)\n",
        "    position = PositionalEncoding(n_units, dropout)\n",
        "    model = FullTransformer(\n",
        "        transformer_stack=TransformerStack(\n",
        "            TransformerBlock(n_units, c(attn), c(ff), dropout), n_blocks\n",
        "        ),\n",
        "        embedding=nn.Sequential(WordEmbedding(n_units, vocab_size), c(position)),\n",
        "        n_units=n_units,\n",
        "        vocab_size=vocab_size,\n",
        "    )\n",
        "\n",
        "    # Initialize parameters with Glorot / fan_avg.\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return model\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "# Data processing\n",
        "\n",
        "\n",
        "def subsequent_mask(size):\n",
        "    \"\"\" helper function for creating the masks. \"\"\"\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype(\"uint8\")\n",
        "    return torch.from_numpy(subsequent_mask) == 0\n",
        "\n",
        "\n",
        "class Batch:\n",
        "    \"Object for holding a batch of data with mask during training.\"\n",
        "\n",
        "    def __init__(self, x, pad=0):\n",
        "        self.data = x\n",
        "        self.mask = self.make_mask(self.data, pad)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_mask(data, pad):\n",
        "        \"Create a mask to hide future words.\"\n",
        "        mask = (data != pad).unsqueeze(-2)\n",
        "        mask = mask & Variable(subsequent_mask(data.size(-1)).type_as(mask.data))\n",
        "        return mask\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "# Some standard modules\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    \"layer normalization, as in: https://arxiv.org/abs/1607.06450\"\n",
        "\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "\n",
        "\n",
        "class ResidualSkipConnectionWithLayerNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    A residual connection followed by a layer norm.\n",
        "    Note for code simplicity the norm is first as opposed to last.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, size, dropout):\n",
        "        super(ResidualSkipConnectionWithLayerNorm, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        \"Apply residual connection to any sublayer with the same size.\"\n",
        "        return x + self.dropout(sublayer(self.norm(x)))\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    This is just an MLP with 1 hidden layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_units, dropout=0.1):\n",
        "        super(MLP, self).__init__()\n",
        "        self.w_1 = nn.Linear(n_units, 2048)\n",
        "        self.w_2 = nn.Linear(2048, n_units)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sNMLdlImB_bi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# argv"
      ]
    },
    {
      "metadata": {
        "id": "GOPf4zpMCBxy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kXvdhrjnCuYK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test_arg_string = 'pt-lmb.py --model=RNN --optimizer=ADAM --initial_lr=0.0001 --batch_size=20 --seq_len=35 --hidden_size=1500 --num_layers=2 --dp_keep_prob=0.35 --save_best'\n",
        "\n",
        "test_arg_string = 'pt-lmb.py --model=GRU --optimizer=SGD_LR_SCHEDULE --initial_lr=10 --batch_size=20 --seq_len=35 --hidden_size=1500 --num_layers=2 --dp_keep_prob=0.35 --save_best'\n",
        "\n",
        "# test_arg_string = 'pt-lmb.py --model=TRANSFORMER --optimizer=SGD_LR_SCHEDULE --initial_lr=20 --batch_size=128 --seq_len=35 --hidden_size=512 --num_layers=6 --dp_keep_prob=0.9 --save_best'\n",
        "\n",
        "sys.argv = test_arg_string.split(' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EOOJHAVZBJAr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ptb-lm.py"
      ]
    },
    {
      "metadata": {
        "id": "kDfa_dsP5f_B",
        "colab_type": "code",
        "outputId": "47d0509d-1269-4200-8008-37bb39cecec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "#!/bin/python\n",
        "# coding: utf-8\n",
        "\n",
        "# Code outline/scaffold for\n",
        "# ASSIGNMENT 2: RNNs, Attention, and Optimization\n",
        "# By Tegan Maharaj, David Krueger, and Chin-Wei Huang\n",
        "# IFT6135 at University of Montreal\n",
        "# Winter 2019\n",
        "#\n",
        "# based on code from:\n",
        "#    https://github.com/deeplearningathome/pytorch-language-model/blob/master/reader.py\n",
        "#    https://github.com/ceshine/examples/blob/master/word_language_model/main.py\n",
        "#    https://github.com/teganmaharaj/zoneout/blob/master/zoneout_word_ptb.py\n",
        "#    https://github.com/harvardnlp/annotated-transformer\n",
        "\n",
        "# GENERAL INSTRUCTIONS:\n",
        "#    - ! IMPORTANT!\n",
        "#      Unless we're otherwise notified we will run exactly this code, importing\n",
        "#      your models from models.py to test them. If you find it necessary to\n",
        "#      modify or replace this script (e.g. if you are using TensorFlow), you\n",
        "#      must justify this decision in your report, and contact the TAs as soon as\n",
        "#      possible to let them know. You are free to modify/add to this script for\n",
        "#      your own purposes (e.g. monitoring, plotting, further hyperparameter\n",
        "#      tuning than what is required), but remember that unless we're otherwise\n",
        "#      notified we will run this code as it is given to you, NOT with your\n",
        "#      modifications.\n",
        "#    - We encourage you to read and understand this code; there are some notes\n",
        "#      and comments to help you.\n",
        "#    - Typically, all of your code to submit should be written in models.py;\n",
        "#      see further instructions at the top of that file / in TODOs.\n",
        "#          - RNN recurrent unit\n",
        "#          - GRU recurrent unit\n",
        "#          - Multi-head attention for the Transformer\n",
        "#    - Other than this file and models.py, you will probably also write two\n",
        "#      scripts. Include these and any other code you write in your git repo for\n",
        "#      submission:\n",
        "#          - Plotting (learning curves, loss w.r.t. time, gradients w.r.t. hiddens)\n",
        "#          - Loading and running a saved model (computing gradients w.r.t. hiddens,\n",
        "#            and for sampling from the model)\n",
        "\n",
        "# PROBLEM-SPECIFIC INSTRUCTIONS:\n",
        "#    - For Problems 1-3, paste the code for the RNN, GRU, and Multi-Head attention\n",
        "#      respectively in your report, in a monospace font.\n",
        "#    - For Problem 4.1 (model comparison), the hyperparameter settings you should run are as follows:\n",
        "#          --model=RNN --optimizer=ADAM --initial_lr=0.0001 --batch_size=20 --seq_len=35 --hidden_size=1500 --num_layers=2 --dp_keep_prob=0.35 --save_best\n",
        "#          --model=GRU --optimizer=SGD_LR_SCHEDULE --initial_lr=10 --batch_size=20 --seq_len=35 --hidden_size=1500 --num_layers=2 --dp_keep_prob=0.35 --save_best\n",
        "#          --model=TRANSFORMER --optimizer=SGD_LR_SCHEDULE --initial_lr=20 --batch_size=128 --seq_len=35 --hidden_size=512 --num_layers=6 --dp_keep_prob=0.9 --save_best\n",
        "#    - In those experiments, you should expect to see approximately the following\n",
        "#      perplexities:\n",
        "#                  RNN: train:  120  val: 157\n",
        "#                  GRU: train:   65  val: 104\n",
        "#          TRANSFORMER:  train:  67  val: 146\n",
        "#    - For Problem 4.2 (exploration of optimizers), you will make use of the\n",
        "#      experiments from 4.1, and should additionally run the following experiments:\n",
        "#          --model=RNN --optimizer=SGD --initial_lr=0.0001 --batch_size=20 --seq_len=35 --hidden_size=1500 --num_layers=2 --dp_keep_prob=0.35\n",
        "#          --model=GRU --optimizer=SGD --initial_lr=10 --batch_size=20 --seq_len=35 --hidden_size=1500 --num_layers=2 --dp_keep_prob=0.35\n",
        "#          --model=TRANSFORMER --optimizer=SGD --initial_lr=20 --batch_size=128 --seq_len=35 --hidden_size=512 --num_layers=6 --dp_keep_prob=.9\n",
        "#          --model=RNN --optimizer=SGD_LR_SCHEDULE --initial_lr=1 --batch_size=20 --seq_len=35 --hidden_size=512 --num_layers=2 --dp_keep_prob=0.35\n",
        "#          --model=GRU --optimizer=ADAM --initial_lr=0.0001 --batch_size=20 --seq_len=35 --hidden_size=1500 --num_layers=2 --dp_keep_prob=0.35\n",
        "#          --model=TRANSFORMER --optimizer=ADAM --initial_lr=0.001 --batch_size=128 --seq_len=35 --hidden_size=512 --num_layers=2 --dp_keep_prob=.9\n",
        "#    - For Problem 4.3 (exloration of hyperparameters), do your best to get\n",
        "#      better validation perplexities than the settings given for 4.1. You may\n",
        "#      try any combination of the hyperparameters included as arguments in this\n",
        "#      script's ArgumentParser, but do not implement any additional\n",
        "#      regularizers/features. You may (and will probably want to) run a lot of\n",
        "#      different things for just 1-5 epochs when you are trying things out, but\n",
        "#      you must report at least 3 experiments on each architecture that have run\n",
        "#      for at least 40 epochs.\n",
        "#    - For Problem 5, perform all computations / plots based on saved models\n",
        "#      from Problem 4.1. NOTE this means you don't have to save the models for\n",
        "#      your exploration, which can make things go faster. (Of course\n",
        "#      you can still save them if you like; just add the flag --save_best).\n",
        "#    - For Problem 5.1, you can modify the loss computation in this script\n",
        "#      (search for \"LOSS COMPUTATION\" to find the appropriate line. Remember to\n",
        "#      submit your code.\n",
        "#    - For Problem 5.3, you must implement the generate method of the RNN and\n",
        "#      GRU.  Implementing this method is not considered part of problems 1/2\n",
        "#      respectively, and will be graded as part of Problem 5.3\n",
        "\n",
        "\n",
        "import argparse\n",
        "import time\n",
        "import collections\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import numpy\n",
        "\n",
        "np = numpy\n",
        "\n",
        "# NOTE ==============================================\n",
        "# This is where your models are imported\n",
        "# from models import RNN, GRU\n",
        "# from models import make_model as TRANSFORMER\n",
        "TRANSFORMER = make_model\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "#\n",
        "# ARG PARSING AND EXPERIMENT SETUP\n",
        "#\n",
        "##############################################################################\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"PyTorch Penn Treebank Language Modeling\")\n",
        "\n",
        "# Arguments you may need to set to run different experiments in 4.1 & 4.2.\n",
        "parser.add_argument(\n",
        "    \"--data\",\n",
        "    type=str,\n",
        "    default=\"data\",\n",
        "    help=\"location of the data corpus. We suggest you change the default\\\n",
        "                    here, rather than passing as an argument, to avoid long file paths.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--model\",\n",
        "    type=str,\n",
        "    default=\"GRU\",\n",
        "    help=\"type of recurrent net (RNN, GRU, TRANSFORMER)\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--optimizer\",\n",
        "    type=str,\n",
        "    default=\"SGD_LR_SCHEDULE\",\n",
        "    help=\"optimization algo to use; SGD, SGD_LR_SCHEDULE, ADAM\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--seq_len\",\n",
        "    type=int,\n",
        "    default=35,\n",
        "    help=\"number of timesteps over which BPTT is performed\",\n",
        ")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=20, help=\"size of one minibatch\")\n",
        "parser.add_argument(\n",
        "    \"--initial_lr\", type=float, default=20.0, help=\"initial learning rate\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--hidden_size\",\n",
        "    type=int,\n",
        "    default=200,\n",
        "    help=\"size of hidden layers. IMPORTANT: for the transformer\\\n",
        "                    this must be a multiple of 16.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--save_best\",\n",
        "    action=\"store_true\",\n",
        "    help=\"save the model for the best validation performance\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--num_layers\",\n",
        "    type=int,\n",
        "    default=2,\n",
        "    help=\"number of hidden layers in RNN/GRU, or number of transformer blocks in TRANSFORMER\",\n",
        ")\n",
        "\n",
        "# Other hyperparameters you may want to tune in your exploration\n",
        "parser.add_argument(\"--emb_size\", type=int, default=200, help=\"size of word embeddings\")\n",
        "parser.add_argument(\n",
        "    \"--num_epochs\", type=int, default=40, help=\"number of epochs to stop after\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--dp_keep_prob\",\n",
        "    type=float,\n",
        "    default=0.35,\n",
        "    help=\"dropout *keep* probability. drop_prob = 1-dp_keep_prob \\\n",
        "                    (dp_keep_prob=1 means no dropout)\",\n",
        ")\n",
        "\n",
        "# Arguments that you may want to make use of / implement more code for\n",
        "parser.add_argument(\"--debug\", action=\"store_true\")\n",
        "parser.add_argument(\n",
        "    \"--save_dir\",\n",
        "    type=str,\n",
        "    default=\"\",\n",
        "    help=\"path to save the experimental config, logs, model \\\n",
        "                    This is automatically generated based on the command line \\\n",
        "                    arguments you pass and only needs to be set if you want a \\\n",
        "                    custom dir name\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--evaluate\",\n",
        "    action=\"store_true\",\n",
        "    help=\"use this flag to run on the test set. Only do this \\\n",
        "                    ONCE for each model setting, and only after you've \\\n",
        "                    completed ALL hyperparameter tuning on the validation set.\\\n",
        "                    Note we are not requiring you to do this.\",\n",
        ")\n",
        "\n",
        "# DO NOT CHANGE THIS (setting the random seed makes experiments deterministic,\n",
        "# which helps for reproducibility)\n",
        "parser.add_argument(\"--seed\", type=int, default=1111, help=\"random seed\")\n",
        "\n",
        "args = parser.parse_args()\n",
        "argsdict = args.__dict__\n",
        "argsdict[\"code_file\"] = sys.argv[0]\n",
        "\n",
        "# Use the model, optimizer, and the flags passed to the script to make the\n",
        "# name for the experimental dir\n",
        "print(\"\\n########## Setting Up Experiment ######################\")\n",
        "flags = [flag.lstrip(\"--\").replace(\"/\", \"\").replace(\"\\\\\", \"\") for flag in sys.argv[1:]]\n",
        "experiment_path = os.path.join(\n",
        "    args.save_dir + \"_\".join([argsdict[\"model\"], argsdict[\"optimizer\"]] + flags)\n",
        ")\n",
        "\n",
        "# Increment a counter so that previous results with the same args will not\n",
        "# be overwritten. Comment out the next four lines if you only want to keep\n",
        "# the most recent results.\n",
        "i = 0\n",
        "if args.model == \"TRANSFORMER\":\n",
        "    i = 2\n",
        "# while os.path.exists(experiment_path + \"_\" + str(i)):\n",
        "#     i += 1\n",
        "experiment_path = experiment_path + \"_\" + str(i)\n",
        "\n",
        "# Creates an experimental directory and dumps all the args to a text file\n",
        "if not os.path.exists(experiment_path):\n",
        "    os.mkdir(experiment_path)\n",
        "print(\"\\nPutting log in %s\" % experiment_path)\n",
        "argsdict[\"save_dir\"] = experiment_path\n",
        "with open(os.path.join(experiment_path, \"exp_config.txt\"), \"w\") as f:\n",
        "    for key in sorted(argsdict):\n",
        "        f.write(key + \"    \" + str(argsdict[key]) + \"\\n\")\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "# Use the GPU if you have one\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using the GPU\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\n",
        "        \"WARNING: You are about to run on cpu, and this will likely run out \\\n",
        "      of memory. \\n You can try setting batch_size=1 to reduce memory usage\"\n",
        "    )\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#\n",
        "# LOADING & PROCESSING\n",
        "#\n",
        "###############################################################################\n",
        "\n",
        "# HELPER FUNCTIONS\n",
        "def _read_words(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        return f.read().replace(\"\\n\", \"<eos>\").split()\n",
        "\n",
        "\n",
        "def _build_vocab(filename):\n",
        "    data = _read_words(filename)\n",
        "\n",
        "    counter = collections.Counter(data)\n",
        "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
        "\n",
        "    words, _ = list(zip(*count_pairs))\n",
        "    word_to_id = dict(zip(words, range(len(words))))\n",
        "    id_to_word = dict((v, k) for k, v in word_to_id.items())\n",
        "\n",
        "    return word_to_id, id_to_word\n",
        "\n",
        "\n",
        "def _file_to_word_ids(filename, word_to_id):\n",
        "    data = _read_words(filename)\n",
        "    return [word_to_id[word] for word in data if word in word_to_id]\n",
        "\n",
        "\n",
        "# Processes the raw data from text files\n",
        "def ptb_raw_data(data_path=None, prefix=\"ptb\"):\n",
        "    train_path = os.path.join(data_path, prefix + \".train.txt\")\n",
        "    valid_path = os.path.join(data_path, prefix + \".valid.txt\")\n",
        "    test_path = os.path.join(data_path, prefix + \".test.txt\")\n",
        "\n",
        "    word_to_id, id_2_word = _build_vocab(train_path)\n",
        "    train_data = _file_to_word_ids(train_path, word_to_id)\n",
        "    valid_data = _file_to_word_ids(valid_path, word_to_id)\n",
        "    test_data = _file_to_word_ids(test_path, word_to_id)\n",
        "    return train_data, valid_data, test_data, word_to_id, id_2_word\n",
        "\n",
        "\n",
        "# Yields minibatches of data\n",
        "def ptb_iterator(raw_data, batch_size, num_steps):\n",
        "    raw_data = np.array(raw_data, dtype=np.int32)\n",
        "\n",
        "    data_len = len(raw_data)\n",
        "    batch_len = data_len // batch_size\n",
        "    data = np.zeros([batch_size, batch_len], dtype=np.int32)\n",
        "    for i in range(batch_size):\n",
        "        data[i] = raw_data[batch_len * i : batch_len * (i + 1)]\n",
        "\n",
        "    epoch_size = (batch_len - 1) // num_steps\n",
        "\n",
        "    if epoch_size == 0:\n",
        "        raise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\")\n",
        "\n",
        "    for i in range(epoch_size):\n",
        "        x = data[:, i * num_steps : (i + 1) * num_steps]\n",
        "        y = data[:, i * num_steps + 1 : (i + 1) * num_steps + 1]\n",
        "        yield (x, y)\n",
        "\n",
        "\n",
        "class Batch:\n",
        "    \"Data processing for the transformer. This class adds a mask to the data.\"\n",
        "\n",
        "    def __init__(self, x, pad=-1):\n",
        "        self.data = x\n",
        "        self.mask = self.make_mask(self.data, pad)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_mask(data, pad):\n",
        "        \"Create a mask to hide future words.\"\n",
        "\n",
        "        def subsequent_mask(size):\n",
        "            \"\"\" helper function for creating the masks. \"\"\"\n",
        "            attn_shape = (1, size, size)\n",
        "            subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype(\"uint8\")\n",
        "            return torch.from_numpy(subsequent_mask) == 0\n",
        "\n",
        "        mask = (data != pad).unsqueeze(-2)\n",
        "        mask = mask & Variable(subsequent_mask(data.size(-1)).type_as(mask.data))\n",
        "        return mask\n",
        "\n",
        "\n",
        "# LOAD DATA\n",
        "print(\"Loading data from \" + args.data)\n",
        "raw_data = ptb_raw_data(data_path=args.data)\n",
        "train_data, valid_data, test_data, word_to_id, id_2_word = raw_data\n",
        "vocab_size = len(word_to_id)\n",
        "print(\"  vocabulary size: {}\".format(vocab_size))\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#\n",
        "# MODEL SETUP\n",
        "#\n",
        "###############################################################################\n",
        "\n",
        "# NOTE ==============================================\n",
        "# This is where your model code will be called. You may modify this code\n",
        "# if required for your implementation, but it should not typically be necessary,\n",
        "# and you must let the TAs know if you do so.\n",
        "if args.model == \"RNN\":\n",
        "    model = RNN(\n",
        "        emb_size=args.emb_size,\n",
        "        hidden_size=args.hidden_size,\n",
        "        seq_len=args.seq_len,\n",
        "        batch_size=args.batch_size,\n",
        "        vocab_size=vocab_size,\n",
        "        num_layers=args.num_layers,\n",
        "        dp_keep_prob=args.dp_keep_prob,\n",
        "    )\n",
        "elif args.model == \"GRU\":\n",
        "    model = GRU(\n",
        "        emb_size=args.emb_size,\n",
        "        hidden_size=args.hidden_size,\n",
        "        seq_len=args.seq_len,\n",
        "        batch_size=args.batch_size,\n",
        "        vocab_size=vocab_size,\n",
        "        num_layers=args.num_layers,\n",
        "        dp_keep_prob=args.dp_keep_prob,\n",
        "    )\n",
        "elif args.model == \"TRANSFORMER\":\n",
        "    if args.debug:  # use a very small model\n",
        "        model = TRANSFORMER(vocab_size=vocab_size, n_units=16, n_blocks=2)\n",
        "    else:\n",
        "        # Note that we're using num_layers and hidden_size to mean slightly\n",
        "        # different things here than in the RNNs.\n",
        "        # Also, the Transformer also has other hyperparameters\n",
        "        # (such as the number of attention heads) which can change it's behavior.\n",
        "        model = TRANSFORMER(\n",
        "            vocab_size=vocab_size,\n",
        "            n_units=args.hidden_size,\n",
        "            n_blocks=args.num_layers,\n",
        "            dropout=1.0 - args.dp_keep_prob,\n",
        "        )\n",
        "    # these 3 attributes don't affect the Transformer's computations;\n",
        "    # they are only used in run_epoch\n",
        "    model.batch_size = args.batch_size\n",
        "    model.seq_len = args.seq_len\n",
        "    model.vocab_size = vocab_size\n",
        "else:\n",
        "    print(\"Model type not recognized.\")\n",
        "\n",
        "# Load existing params from .pt file.\n",
        "load_model_params = True\n",
        "if load_model_params:\n",
        "    pretrained_state_dict = torch.load(os.path.join(\"./PB4_1/\", args.save_dir, \"best_params.pt\"))\n",
        "    model.load_state_dict(pretrained_state_dict)\n",
        "    model.eval()\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# LOSS FUNCTION\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "if args.optimizer == \"ADAM\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.initial_lr)\n",
        "\n",
        "# LEARNING RATE SCHEDULE\n",
        "lr = args.initial_lr\n",
        "lr_decay_base = 1 / 1.15\n",
        "m_flat_lr = 14.0  # we will not touch lr for the first m_flat_lr epochs\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "########## Setting Up Experiment ######################\n",
            "\n",
            "Putting log in GRU_SGD_LR_SCHEDULE_model=GRU_optimizer=SGD_LR_SCHEDULE_initial_lr=10_batch_size=20_seq_len=35_hidden_size=1500_num_layers=2_dp_keep_prob=0.35_save_best_0\n",
            "Using the GPU\n",
            "Loading data from data\n",
            "  vocabulary size: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aL_ZbNGJ5h60",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# sample"
      ]
    },
    {
      "metadata": {
        "id": "gCHWrdf6TeQT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#\n",
        "# DEFINE COMPUTATIONS FOR PROCESSING ONE EPOCH\n",
        "#\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"\n",
        "    Wraps hidden states in new Tensors, to detach them from their history.\n",
        "\n",
        "    This prevents Pytorch from trying to backpropagate into previous input\n",
        "    sequences when we use the final hidden states from one mini-batch as the\n",
        "    initial hidden states for the next mini-batch.\n",
        "\n",
        "    Using the final hidden states in this way makes sense when the elements of\n",
        "    the mini-batches are actually successive subsequences in a set of longer sequences.\n",
        "    This is the case with the way we've processed the Penn Treebank dataset.\n",
        "    \"\"\"\n",
        "    if isinstance(h, Variable):\n",
        "        return h.detach_()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "\n",
        "def run_epoch(model, data, is_train=False, lr=1.0):\n",
        "    \"\"\"\n",
        "    One epoch of training/validation (depending on flag is_train).\n",
        "    \"\"\"\n",
        "    if is_train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    epoch_size = ((len(data) // model.batch_size) - 1) // model.seq_len\n",
        "    start_time = time.time()\n",
        "    if args.model != \"TRANSFORMER\":\n",
        "        hidden = model.init_hidden()\n",
        "        hidden = hidden.to(device)\n",
        "    costs = 0.0\n",
        "    iters = 0\n",
        "    losses = []\n",
        "\n",
        "    # LOOP THROUGH MINIBATCHES\n",
        "    for step, (x, y) in enumerate(ptb_iterator(data, model.batch_size, model.seq_len)):\n",
        "        if args.model == \"TRANSFORMER\":\n",
        "            batch = Batch(torch.from_numpy(x).long().to(device))\n",
        "            model.zero_grad()\n",
        "            outputs = model.forward(batch.data, batch.mask).transpose(1, 0)\n",
        "            # print (\"outputs.shape\", outputs.shape)\n",
        "        else:\n",
        "            inputs = (\n",
        "                torch.from_numpy(x.astype(np.int64))\n",
        "                .transpose(0, 1)\n",
        "                .contiguous()\n",
        "                .to(device)\n",
        "            )  # .cuda()\n",
        "            model.zero_grad()\n",
        "            hidden = repackage_hidden(hidden)\n",
        "            outputs, hidden = model(inputs, hidden)\n",
        "\n",
        "        targets = (\n",
        "            torch.from_numpy(y.astype(np.int64)).transpose(0, 1).contiguous().to(device)\n",
        "        )  # .cuda()\n",
        "        tt = torch.squeeze(targets.view(-1, model.batch_size * model.seq_len))\n",
        "\n",
        "        # LOSS COMPUTATION\n",
        "        # This line currently averages across all the sequences in a mini-batch\n",
        "        # and all time-steps of the sequences.\n",
        "        # For problem 5.3, you will (instead) need to compute the average loss\n",
        "        # at each time-step separately.\n",
        "        loss = loss_fn(outputs.contiguous().view(-1, model.vocab_size), tt)\n",
        "        costs += loss.data.item() * model.seq_len\n",
        "        losses.append(costs)\n",
        "        iters += model.seq_len\n",
        "        if args.debug:\n",
        "            print(step, loss)\n",
        "        if is_train:  # Only update parameters if training\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
        "            if args.optimizer == \"ADAM\":\n",
        "                optimizer.step()\n",
        "            else:\n",
        "                for p in model.parameters():\n",
        "                    if p.grad is not None:\n",
        "                        p.data.add_(-lr, p.grad.data)\n",
        "            if step % (epoch_size // 10) == 10:\n",
        "                print(\n",
        "                    \"step: \"\n",
        "                    + str(step)\n",
        "                    + \"\\t\"\n",
        "                    + \"loss (sum over all examples' seen this epoch):\"\n",
        "                    + str(costs)\n",
        "                    + \"\\t\"\n",
        "                    + \"speed (wps):\"\n",
        "                    + str(iters * model.batch_size / (time.time() - start_time))\n",
        "                )\n",
        "    return np.exp(costs / iters), losses\n",
        "\n",
        "def graph_losses(model, data, is_train=False, lr=1.0):\n",
        "    \"\"\"\n",
        "    One epoch of training/validation (depending on flag is_train).\n",
        "    \"\"\"\n",
        "    if is_train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    epoch_size = ((len(data) // model.batch_size) - 1) // model.seq_len\n",
        "    start_time = time.time()\n",
        "    if args.model != \"TRANSFORMER\":\n",
        "        hidden = model.init_hidden()\n",
        "        hidden = hidden.to(device)\n",
        "    costs = 0.0\n",
        "    iters = 0\n",
        "    losses = []\n",
        "    \n",
        "    losses_per_t = torch.tensor([0.0] * model.seq_len)\n",
        "    total_steps = 0\n",
        "\n",
        "    # LOOP THROUGH MINIBATCHES\n",
        "    for step, (x, y) in enumerate(ptb_iterator(data, model.batch_size, model.seq_len)):\n",
        "        if args.model == \"TRANSFORMER\":\n",
        "            batch = Batch(torch.from_numpy(x).long().to(device))\n",
        "            model.zero_grad()\n",
        "            outputs = model.forward(batch.data, batch.mask).transpose(1, 0)\n",
        "            # print (\"outputs.shape\", outputs.shape)\n",
        "        else:\n",
        "            inputs = (\n",
        "                torch.from_numpy(x.astype(np.int64))\n",
        "                .transpose(0, 1)\n",
        "                .contiguous()\n",
        "                .to(device)\n",
        "            )  # .cuda()\n",
        "            model.zero_grad()\n",
        "            hidden = repackage_hidden(hidden)\n",
        "            outputs, hidden = model(inputs, hidden)\n",
        "\n",
        "        targets = (\n",
        "            torch.from_numpy(y.astype(np.int64)).transpose(0, 1).contiguous().to(device)\n",
        "        )  # .cuda()\n",
        "        tt = torch.squeeze(targets.view(-1, model.batch_size * model.seq_len))\n",
        "\n",
        "        # LOSS COMPUTATION\n",
        "        # This line currently averages across all the sequences in a mini-batch\n",
        "        # and all time-steps of the sequences.\n",
        "        # For problem 5.3, you will (instead) need to compute the average loss\n",
        "        # at each time-step separately.\n",
        "        loss = loss_fn(outputs.contiguous().view(-1, model.vocab_size), tt)\n",
        "        costs += loss.data.item() * model.seq_len\n",
        "        losses.append(costs)\n",
        "        iters += model.seq_len\n",
        "        \n",
        "        # Calculate loss per time step.\n",
        "        if not is_train:\n",
        "            with torch.no_grad():\n",
        "                for i in range(model.seq_len):\n",
        "                    losses_per_t[i] += nn.functional.cross_entropy(outputs[i], targets[i])\n",
        "                total_steps += 1\n",
        "                \n",
        "    if not is_train:\n",
        "        plt.plot(list(range(1,36)), [l / total_steps for l in losses_per_t.numpy()])\n",
        "        plt.xlabel('Timestep')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Loss per Timestep for ' + args.model)\n",
        "        plt.show()\n",
        "        \n",
        "def graph_gradients(model, data):\n",
        "    model.train()\n",
        "    epoch_size = ((len(data) // model.batch_size) - 1) // model.seq_len\n",
        "\n",
        "    \n",
        "    hidden = model.init_hidden()\n",
        "    hidden = hidden.to(device)\n",
        "    \n",
        "    for step, (x, y) in enumerate(ptb_iterator(data, model.batch_size, model.seq_len)):\n",
        "        inputs = (\n",
        "            torch.from_numpy(x.astype(np.int64))\n",
        "                .transpose(0, 1)\n",
        "                .contiguous()\n",
        "                .to(device)\n",
        "        )\n",
        "        model.zero_grad()\n",
        "        hidden = repackage_hidden(hidden)\n",
        "        outputs, hidden = model(inputs, hidden)\n",
        "\n",
        "        targets = (\n",
        "            torch.from_numpy(y.astype(np.int64)).transpose(0, 1).contiguous().to(device)\n",
        "        )\n",
        "        \n",
        "        tt = torch.squeeze(targets.view(-1, model.batch_size * model.seq_len))\n",
        "\n",
        "        # LOSS COMPUTATION\n",
        "        # This line currently averages across all the sequences in a mini-batch\n",
        "        # and all time-steps of the sequences.\n",
        "        # For problem 5.3, you will (instead) need to compute the average loss\n",
        "        # at each time-step separately.\n",
        "        \n",
        "        # loss = loss_fn(outputs[-1], targets[-1])\n",
        "        loss = loss_fn(outputs[-1].contiguous().view(-1, model.vocab_size), torch.squeeze(targets[-1].view(model.batch_size)))\n",
        "        \n",
        "        \n",
        "        '''loss = loss_fn(outputs.contiguous().view(-1, model.vocab_size), tt)\n",
        "        costs += loss.data.item() * model.seq_len\n",
        "        losses.append(costs)\n",
        "        iters += model.seq_len\n",
        "        if args.debug:\n",
        "            print(step, loss)'''\n",
        "        \n",
        "        loss.backward()\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
        "            \n",
        "        '''grads = []\n",
        "        for i in range(model.seq_len):\n",
        "            norm = 0.0\n",
        "            for j in range(model.num_layers):\n",
        "                if model.hidden_results[j][i].requires_grad:\n",
        "                    # print(model.hidden_results[j][i].grad)\n",
        "                    norm += model.hidden_results[j][i].grad.norm()\n",
        "            grads.append(norm)\n",
        "\n",
        "        #print(grads)\n",
        "        plt.plot(grads)\n",
        "        plt.show()'''\n",
        "            \n",
        "            \n",
        "        '''for p in model.parameters():\n",
        "                if p.grad is not None:\n",
        "                    p.data.add_(-lr, p.grad.data)'''\n",
        "        break\n",
        "        \n",
        "    total_grads = []\n",
        "    for i in range(0, len(grads), 2):\n",
        "        total_grads += [grads[i] + grads[i+1]]\n",
        "    plt.plot(list(range(1,36)), list(reversed(total_grads)))\n",
        "    plt.xlabel('Timestep')\n",
        "    plt.ylabel('Gradient Norm of Hidden States')\n",
        "    plt.title('Gradients for ' + args.model)\n",
        "    plt.show()\n",
        "\n",
        "def generate_sequence(model, sample_len):\n",
        "    model.seq_len = 1\n",
        "    model.eval()\n",
        "    \n",
        "    # with torch.no_grad():\n",
        "    hidden = model.init_hidden()\n",
        "    hidden = hidden.to(device)\n",
        "    next_hidden = None\n",
        "\n",
        "    word_ids = [2]\n",
        "\n",
        "    for i in range(sample_len):\n",
        "        inputs = torch.ones((model.seq_len, model.batch_size), dtype=torch.int64).cpu()\n",
        "        inputs[0][0] = word_ids[-1]\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        outputs, next_hidden = model(inputs, hidden)\n",
        "\n",
        "        outputs = outputs.cpu()\n",
        "\n",
        "        next_word = torch.multinomial(nn.functional.softmax(outputs[0,0], dim=-1), 1).squeeze()\n",
        "\n",
        "        word_ids += [next_word.item()]\n",
        "\n",
        "        hidden = next_hidden\n",
        "        \n",
        "    return ' '.join([id_2_word[x] for x in word_ids[1:]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zZkDAb0TecSZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Results"
      ]
    },
    {
      "metadata": {
        "id": "FbVKeUJdedgj",
        "colab_type": "code",
        "outputId": "6ea1fccc-669b-4e1b-edac-3724d126dcd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#\n",
        "# RUN MAIN LOOP (TRAIN AND VAL)\n",
        "#\n",
        "###############################################################################\n",
        "\n",
        "print(\"\\n########## Running Problem 5 ##########################\")\n",
        "train_ppls = []\n",
        "train_losses = []\n",
        "val_ppls = []\n",
        "val_losses = []\n",
        "best_val_so_far = np.inf\n",
        "times = []\n",
        "grads = []\n",
        "\n",
        "# In debug mode, only run one epoch\n",
        "if args.debug:\n",
        "    num_epochs = 1\n",
        "else:\n",
        "    num_epochs = args.num_epochs\n",
        "\n",
        "# RUN MODEL ON VALIDATION DATA\n",
        "# val_ppl, val_loss = run_epoch(model, valid_data)\n",
        "# print('val_ppl', val_ppl)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "########## Running Problem 5 ##########################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ADmcCGAUd35f",
        "colab_type": "code",
        "outputId": "cd41452f-f870-4cfd-b03a-92d15478ef92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "graph_losses(model, valid_data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xbPZImdvemMC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "2c048add-1e3f-4258-86ed-a2008a8326a0"
      },
      "cell_type": "code",
      "source": [
        "sent = None\n",
        "if args.model != \"TRANSFORMER\":\n",
        "    for slen in [35, 70]:\n",
        "        for _ in range(10):\n",
        "            sent = generate_sequence(model, slen)\n",
        "            print(sent)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it 's issue to get her <unk> to hide experience we 're <unk> to very competitive says michael <unk> iii of solidarity 's <unk> basketball message in new york <eos> this is is <unk> <eos>\n",
            "it 's hard to tell the truth says john goldberg a mining analyst at <unk> & co. a chicago firm there 's been a large program that is pushing for a delicate carpets <eos> junior\n",
            "some californians have speculated that the default rate will be a <unk> order from near the irs and the newly held government of technology <eos> in addition N years ago will be the bank of\n",
            "the company has sued a temporary chunk on a two-year entity in predicting in the fourth quarter of maintaining discount sales citing imported variety of other and quist beneficial or wire <unk> chips <eos> the\n",
            "there was a lot of N then room for nine times were the same time but are favorable consideration <eos> traders said with investors are greeted by some market in the u.s. <eos> gte corp.\n",
            "the theory is subject to removing definitive guidelines for birth adjustments the washington monetary court said <eos> the company 's actions include industrywide news in health people and the nation 's central national association of\n",
            "licensing v. <unk> inc <eos> no <unk> has been real-estate forecasts by the september u.s. brokerage institutions are pulling off in the face of <unk> stock markets <eos> a setback follows the fourth problem in\n",
            "they 're trying to cut their opposition to continue loans to run they says even though the extra project ca n't be very easy <eos> john c. <unk> of san francisco messiah 's need to\n",
            "it 's well true that a <unk> poll the compound economy is confiscated down to have a base on about N N annually but the announcement <unk> <eos> new homes was priced across the indictment\n",
            "you 're very happy if we 'll go two judges on writing capitalism says rep. burton chairman who would be mexico 's president <eos> alongside for course in china <eos> we think about N pounds\n",
            "if you 're n't what can happen then them i 'll find your way mr. steinhardt <unk> an interest he says <eos> with watch some arrangements the color is n't very good for the matter on remove they always want to keep the money <eos> it 's too easy mr. carpenter says in a telephone interview after up the government has attempting to <unk> the <unk> seller of the battle\n",
            "but serious purchases should be sluggish in recent weeks if they do n't seem to be selective risks or thrifts else to be difficulty sophisticated japanese tickets to make a more competitive decisions <eos> we 're confident that economic conditions are going to be broadly to our work on our confusing goals rather than deal <eos> a university of financial circles houston not probably have enough approval to make <unk>\n",
            "the latter stands by some of N companies on the country is diverted away <eos> they minority holders off a boost of this type to N N of every tax-free flow in the standard field if it plans to keep the <unk> <unk> a loan basis <eos> if he is committed to insist that stock prices would be limited to <unk> costs mainly and reduce <unk> <eos> but he says\n",
            "however what is still the large policy to be the <unk> of your wives that allows in god to independent germany but n't he is frustrated <eos> everyone is a teacher who wants to go out from a trade business that luck part of the abuse of commissioners <eos> but not this world does n't mean they 're a <unk> prosecutorial nation <eos> four republican candidates are aiming to <unk>\n",
            "terry <unk> & co. said the resignation in the new york stock exchange was a victim of two kan. units and six months <eos> in a statement prepared to federal court protection for antitrust financial condition pending <unk> and owner of <unk> innopac and take their own office <eos> in connecticut its case in the new-issue area following the report a tentative panel were avoiding technical preference and through the\n",
            "campeau exploration inc. charlotte ii named <unk> mich. chief executive officer in january N was elected to a chemicals subcommittee to take a salary of the food and drug administration to refuse <eos> as a first vice president of <unk> george weekes may be chairman of the american aviation institute to a unit of the company <eos> although a other experts win by january july the new u.s. attorney ernest\n",
            "but it was unclear that the investor may respond off this japanese purchases <eos> it 's either to tell how many kind about their relationship to us those <eos> to see even higher japanese banks should prefer to invest on the page of their introduction common stock to meet acquisitions on the table <eos> the americans whose u.s. partners <unk> it mexico a fat and a state-owned group move $\n",
            "the prospectus also is filed with a lawsuit here led to a letter of intent was that <unk> owned by the supreme court decision offered to consider the assigned case agent aimed at eddie and consulting suisse of the brokerage firm <eos> under the battle cross & <unk> pro faces a lawsuit to prevent parties from <unk> <unk> a fast-growing <unk> manufacturer of texas national music victims and a management\n",
            "ralston is refusal to resume the <unk> market for extraordinary work on the planet and an elaborate basis while our approval and four <unk> claimants applied into news and at least to even <unk> majority art <unk> locked mostly a <unk> <unk> by a york student or target for one of jerry <eos> 's original alternative you become peter <unk> 's general scandal of <unk> the family 's portrait of\n",
            "it came an elaborate out early or N to N <eos> alaska <unk> had been fighting about the big board side of the old citizen exporter of <unk> arms <eos> that and <unk> through the quake 's main business <unk> and the unit of the view bell areas led by charleston to glory have become u.s. deficit mostly <eos> in recent weeks the technology currency closed nov. N N at\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tA_PDL-jenYl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1364
        },
        "outputId": "f319e3af-86c4-44c6-a947-e211f4307e6a"
      },
      "cell_type": "code",
      "source": [
        "grads = []\n",
        "if args.model != \"TRANSFORMER\":\n",
        "    graph_gradients(model, train_data)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-9073a5586bee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"TRANSFORMER\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgraph_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-da5e21f2eefa>\u001b[0m in \u001b[0;36mgraph_gradients\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mtotal_grads\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Timestep'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Gradient Norm of Hidden States'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2809\u001b[0m     return gca().plot(\n\u001b[1;32m   2810\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2811\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (35,) and (1,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFOCAYAAABNFY7/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njBpYUMuoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "eby_6tSaiuRg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total_grads = []\n",
        "for i in range(0, len(grads), 2):\n",
        "    total_grads += [grads[i] + grads[i+1]]\n",
        "    \n",
        "total_grads2 = []\n",
        "for i in range(0, len(gru_grads), 2):\n",
        "    total_grads2 += [gru_grads[i] + gru_grads[i+1]]\n",
        "    \n",
        "total_grads = [t/max(total_grads) for t in total_grads]\n",
        "total_grads2 = [t/max(total_grads2) for t in total_grads2]\n",
        "    \n",
        "plt.plot(list(range(1,36)), list(reversed(total_grads)), label='RNN')\n",
        "plt.plot(list(range(1,36)), list(reversed(total_grads2)), label='GRU')\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel('Gradient Norm of Hidden States')\n",
        "plt.title('Normalized Gradients for RNN and GRU')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}